# Compiling languages into Vector space

The other day I was in a brief conversion about AI as some might do these days. Though I find these conversations very wildly based on your understanding of the world. This conversion was with a group of Computer Science PhD students who are all magnitudes smarter and knowledgeable about these subjects than I am. But one who's name I am happy to patch there name in if they would like, said that LLM's or more commonly known as "Ai" these days "it is a fuzzy database that try to search for close match". Which I found as a very interesting way of looking at it. Some background I have taken almost no classes on AI and my mental model for it was really just based on this [3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) series. Which may not be 100% correct but my limited understanding of Calculus, Linear ALgebra, Statistics and Computers Science I was able to follow along and make sense of at a high level.

Anyways this gives me an idea that I will do my best to explain. But my skill in expressing ideas in written english isn't a strength of mine so please ask for clarification if I skipped something. I am very Dyslexic and find the ambiguities in English and there assumed knowledge or context frustrating and believe this is what leads to what is referred to as hallucinations. Which has me wondering if we train or compile different language for it to search through could we spread out these collisions and almost guarantee correct responses. Effectively storing information in the multidimensional vector space that these models are searching though. I also think training it on natural languages like English, Chinese isn't what I would do because of at least the ambiguities in English I know about I don't know if this is true in other languages. 

I think Math is the language we should really target for querying into. As it is the one language we all rely on weather we know or want to admit it. But it is often the language that is not truly appreciated, hard to learn and not always well taught. But it's just a language, a syntax we use to express ideas and our mind is where the beauty really lives. Which is why I have described Math as a sort of inside joke. As I know some of the syntax but really just enough to get where I am now and haven't found the drive to explore it for the sake of self exploration as many do and I think thats where the true love and understanding of math comes from. This is partly because I have been two narrow minded in my return for my Computer Science degree. I am trying to build a thing and was really on a quest for what  tools and knowledge I need to build the experience I wanted to use and share with others as an alternative view of what computers could be if we break as many rules that make sense to deliver the experience that is helpful to as many as possible. Anyways i'm a little distracted as my ADD does.

What I was trying to get at is the math we see on paper and on proofs is really an expression of ideas and a way to order those ideas in a consistent way. Though we seem to teach or introduce it in the same syntax. It's a language we are all forced to learn at some point and quickly forget as computers or a very few people in the world do it for most of us. Though one thing I find ironic is that computers don't really do it correctly in the sake of speed (Floating Point) which is also the work horse of AI funny enough. Math also takes different forms this days, Theorem provers, programming languages and i'm sure other forms I don't know of.

So my idea and really more of a question is what alternative syntax or readable representation of Math could we have? One that is preferable formally grammatically correct could we express and then train LLM's to map (compile) this language into the multiple dimension vector space that they later query into. One that it is spread out enough to be probabilistically correct almost all of the time. So that we can explore math as a sort of functional graph traversal of a language.

I don't even know if this is possible and maybe there is a math proof that I can site here showing why it's impossible. But if an LLM is a series of mathematical operations to map languages (series of tokens) into this multi dimension vector universe. Well instead of trying to try optimize edge cases to trying to correct flaws in English and other context sensitive natural languages that we as humans can usually disambiguate based on our context and assumed knowledge. What if we iterate on the language and layer these languages to work backwards to the languages we more commonly express our selves with like English and Math.

A brief but relevant detour, Programming computers is a series of layering languages. High level languages like Python, C, Rust, Haskell, Swift, C++, JavaScript. This list goes on but is maybe shorter then it should be. But one thing all these languages have in common is the common goal having to run on a CPU. One common shortcut in this end goal here is a technology called LLVM which many of these languages use as whats called an Intermediate representation or another language which is harder to write but a little bit easier for the compute to speak. This then gets translated to assembly language which is commonly thought of as the language that the CPU speaks. But this is often translated again into something called micro operations which the CPU executes and preforms is computation and this is where my understanding of hardware ends and I like to think of as where the [Golem](https://en.wikipedia.org/wiki/Golem) begins. Credit to [Professor Panchekha](https://pavpanchekha.com) for much of this insight on the layers of languages and the idea that CPU's are just Golems. 

So this idea of layering languages is not new. But what if instead of compiling languages to this language designed for computation what if we design a series of languages that maps to vector space which we can compose together working backwards. Building up a language that we can use to correctly query information out of this vector space. If you think of vector spaces as a discrete but infintie space of mathematical vectors that we have only just started to figure out how to map natural languages into. Well if we can figure out a sort of assembly language to define and query information into this space and layer these languages up to something that could be English, Russian, Chinese, and the Holy grail IMO Math it's self. So that we can build and make correct queries into this space. Allowing for faster exploration of information. And my grade school understanding of something called Type Theory may of shown it is possible to express the rules need for on what these queries might be or how they compose with something called Lambda Cube and Calculus of constructions. Now can we A find a way to compose vector space in a way that we can impose the rules of type theory and then work backwards to correctly enforcing the implicit rules of our natural languages? What are these layers of languages maybe Principia Mathematica is a starting place to look at. I am defiantly building an idea off a bunch of things I really don't understand but find interesting. So maybe a bad idea but maybe it will provoke a better idea for someone else.  Curious to hear your thoughts or tomatoes.

Thanks,
Zane